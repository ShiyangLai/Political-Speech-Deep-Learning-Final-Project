{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "e6d33d11-934d-48c8-bb2d-3c0f0f8ba956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchaudio librosa\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from pathlib import Path\n",
    "import torchaudio\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use(['nature', 'science', 'no-latex'])\n",
    "plt.rcParams['font.family'] = 'Times New Roman'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "13e0aebe-f781-44a9-9c6f-a4605887a5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_files(path: str, label:str, resample_rate=16000, duration=60, slice_length=600, offset=0):\n",
    "    dataset = []\n",
    "    walker = sorted(str(p) for p in Path(path).glob(f'*.mp3'))\n",
    "\n",
    "    for i, file_path in enumerate(walker):\n",
    "        path, filename = os.path.split(file_path)\n",
    "        speaker = path.split('/')[-1]\n",
    "        # Load audio as slices\n",
    "        for i, t in enumerate(range(offset, slice_length+offset, duration)):\n",
    "            waveform, _ = librosa.load(file_path, sr=resample_rate, offset=t, duration=duration, mono=True)\n",
    "            dataset.append([waveform, resample_rate, label, filename.replace('.mp3', ''), i])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "db89a3ba-9f9a-499f-b09f-38d5e16bc66a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LyndonBJohnson = load_audio_files(f'../audio/Lyndon B. Johnson', 'Lyndon B. Johnson')\n",
    "# RichardMNixon = load_audio_files(f'../audio/Richard M. Nixon', 'Richard M. Nixon')\n",
    "# BillClinton = load_audio_files(f'../audio/Bill Clinton', 'Bill Clinton')\n",
    "# JohnFKennedy = load_audio_files(f'../audio/John F. Kennedy', 'John F. Kennedy')\n",
    "# RenaldReagan = load_audio_files('../audio/Ronald Reagan', 'Ronald Reagan')\n",
    "# GeorgeHWBush = load_audio_files('../audio/George H. W. Bush', 'George H. W. Bush')\n",
    "# GeorgeWBush = load_audio_files('../audio/George W. Bush', 'George W. Bush')\n",
    "# BarackObama = load_audio_files('../audio/Barack Obama', 'Barack Obama')\n",
    "# FranklinDRoosevelt = load_audio_files('../audio/Franklin D. Roosevelt', 'Franklin D. Roosevelt')\n",
    "JimmyCarter = load_audio_files('../audio/Jimmy Carter', 'Jimmy Carter', slice_length=25*60, offset=180)utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "1ab37802-0cee-468b-83d3-971769c943f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainloader_LyndonBJohnson = torch.utils.data.DataLoader(LyndonBJohnson, batch_size=1, shuffle=True, num_workers=2)\n",
    "# trainloader_RichardMNixon = torch.utils.data.DataLoader(RichardMNixon, batch_size=1, shuffle=True, num_workers=2)\n",
    "# trainloader_BillClinton = torch.utils.data.DataLoader(BillClinton, batch_size=1, shuffle=True, num_workers=2)\n",
    "# trainloader_JohnFKennedy = torch.utils.data.DataLoader(JohnFKennedy, batch_size=1, shuffle=True, num_workers=2)\n",
    "# trainloader_RenaldReagan = torch.utils.data.DataLoader(RenaldReagan, batch_size=1, shuffle=True, num_workers=2)\n",
    "# trainloader_GeorgeHWBush = torch.utils.data.DataLoader(GeorgeHWBush, batch_size=1, shuffle=True, num_workers=2)\n",
    "# trainloader_GeorgeWBush = torch.utils.data.DataLoader(GeorgeWBush, batch_size=1, shuffle=True, num_workers=2)\n",
    "# trainloader_BarackObama = torch.utils.data.DataLoader(BarackObama, batch_size=1, shuffle=True, num_workers=2)\n",
    "# trainloader_FranklinDRoosevelt = torch.utils.data.DataLoader(FranklinDRoosevelt, batch_size=1, shuffle=True, num_workers=2)\n",
    "trainloader_JimmyCarter = torch.utils.data.DataLoader(JimmyCarter, batch_size=1, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "9909f620-e95e-4842-adab-cf55d14b634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrogram_images(trainloader, label_dir):\n",
    "    # make directory\n",
    "    directory = f'dataset/audio_images/spectrogram/{label_dir}/'\n",
    "    if(os.path.isdir(directory)):\n",
    "        print(\"Data exists for\", label_dir)\n",
    "    else:\n",
    "        os.makedirs(directory, mode=0o777, exist_ok=True)\n",
    "        \n",
    "        for i, data in enumerate(trainloader):\n",
    "            waveform = data[0].numpy().flatten()\n",
    "            sample_rate = data[1][0]\n",
    "            label = data[2]\n",
    "\n",
    "            # create transformed waveforms\n",
    "            spectrogram = librosa.feature.mfcc(y=waveform, sr=sample_rate.numpy())\n",
    "            plt.imsave(f'dataset/audio_images/spectrogram/{label_dir}/spec_img{i}.png', spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "378a5306-3bb3-477d-852a-a6c8230e3525",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create_spectrogram_images(trainloader_LyndonBJohnson, 'Lyndon B. Johnson')\n",
    "# create_spectrogram_images(trainloader_RichardMNixon, 'Richard M. Nixon')\n",
    "# create_spectrogram_images(trainloader_BillClinton, 'Bill Clinton')\n",
    "# create_spectrogram_images(trainloader_JohnFKennedy, 'John F. Kennedy')\n",
    "# create_spectrogram_images(trainloader_RenaldReagan, 'Ronald Reagan')\n",
    "# create_spectrogram_images(trainloader_GeorgeHWBush, 'George H. W. Bush')\n",
    "# create_spectrogram_images(trainloader_GeorgeWBush, 'George W. Bush')\n",
    "# create_spectrogram_images(trainloader_BarackObama, 'Barack Obama')\n",
    "# create_spectrogram_images(trainloader_FranklinDRoosevelt, 'Franklin D. Roosevelt')\n",
    "create_spectrogram_images(trainloader_JimmyCarter, 'Jimmy Carter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "edab9081-bb5b-47eb-ac2f-943e0042478b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 497\n",
      "    Root location: dataset/audio_images/spectrogram/\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "# load preprocessed data\n",
    "from torchvision import datasets, transforms\n",
    "presidents_dataset = datasets.ImageFolder(\n",
    "    root='dataset/audio_images/spectrogram/',\n",
    "    transform=transforms.Compose([transforms.ToTensor()\n",
    "                                  ])\n",
    ")\n",
    "print(presidents_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "f6d2f7b4-1f12-43ba-9c96-62b5669f2115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 397\n",
      "Testing size: 100\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.8 * len(presidents_dataset))\n",
    "test_size = len(presidents_dataset) - train_size\n",
    "presidents_train_dataset, presidents_test_dataset = torch.utils.data.random_split(presidents_dataset, [train_size, test_size])\n",
    "print(\"Training size:\", len(presidents_train_dataset))\n",
    "print(\"Testing size:\",len(presidents_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "046c977c-eeca-4aa1-abed-9c357ca0ba12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({7: 45, 1: 34, 3: 37, 9: 40, 0: 40, 5: 36, 4: 43, 8: 41, 2: 43, 6: 38})"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# labels in training set\n",
    "train_classes = [label for _, label in presidents_train_dataset]\n",
    "Counter(train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "a429b16f-ba79-4c62-a16e-ef068d3245f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Barack Obama',\n",
       " 'Bill Clinton',\n",
       " 'Franklin D. Roosevelt',\n",
       " 'George H. W. Bush',\n",
       " 'George W. Bush',\n",
       " 'Jimmy Carter',\n",
       " 'John F. Kennedy',\n",
       " 'Lyndon B. Johnson',\n",
       " 'Richard M. Nixon',\n",
       " 'Ronald Reagan']"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "presidents_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "a9034e28-8b30-48a9-9f71-00ea88cd9404",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    presidents_train_dataset,\n",
    "    batch_size=10,\n",
    "    num_workers=2,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    presidents_test_dataset,\n",
    "    batch_size=10,\n",
    "    num_workers=2,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "e8e3e50d-55d7-412d-8c3e-d9c7b1ff8e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        conv_layers = []\n",
    "        # First Convolution Block with Relu and Batch Norm. Use Kaiming Initialization\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        init.kaiming_normal_(self.conv1.weight, a=0.1)\n",
    "        self.conv1.bias.data.zero_()\n",
    "        conv_layers += [self.conv1, self.relu1, self.bn1]\n",
    "        # Second Convolution Block\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        init.kaiming_normal_(self.conv2.weight, a=0.1)\n",
    "        self.conv2.bias.data.zero_()\n",
    "        conv_layers += [self.conv2, self.relu2, self.bn2]\n",
    "        # Second Convolution Block\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        init.kaiming_normal_(self.conv3.weight, a=0.1)\n",
    "        self.conv3.bias.data.zero_()\n",
    "        conv_layers += [self.conv3, self.relu3, self.bn3]\n",
    "        # Second Convolution Block\n",
    "        self.conv4 = nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        init.kaiming_normal_(self.conv4.weight, a=0.1)\n",
    "        self.conv4.bias.data.zero_()\n",
    "        conv_layers += [self.conv4, self.relu4, self.bn4]\n",
    "        # Linear Classifier\n",
    "        self.ap = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.lin = nn.Linear(in_features=64, out_features=10)\n",
    "\n",
    "        # Wrap the Convolutional Blocks\n",
    "        self.conv = nn.Sequential(*conv_layers)\n",
    " \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Run the convolutional blocks\n",
    "        x = self.conv(x)\n",
    "        # Adaptive pool and flatten for input to linear layer\n",
    "        x = self.ap(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        # Linear layer\n",
    "        x = self.lin(x)\n",
    "        # Final output\n",
    "        return x\n",
    "model = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "422a6de7-e361-42fb-a8ed-c99a4e62b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, train_dl, num_epochs):\n",
    "    # Loss Function, Optimizer and Scheduler\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001,\n",
    "                                                steps_per_epoch=int(len(train_dl)),\n",
    "                                                epochs=num_epochs,\n",
    "                                                anneal_strategy='linear')\n",
    "\n",
    "    # Repeat for each epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_prediction = 0\n",
    "        total_prediction = 0\n",
    "\n",
    "        # Repeat for each batch in the training set\n",
    "        for i, data in enumerate(train_dl):\n",
    "            # Get the input features and target labels, and put them on the GPU\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Normalize the inputs\n",
    "            inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "            inputs = (inputs - inputs_m) / inputs_s\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Keep stats for Loss and Accuracy\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Get the predicted class with the highest score\n",
    "            _, prediction = torch.max(outputs,1)\n",
    "            # Count of predictions that matched the target label\n",
    "            correct_prediction += (prediction == labels).sum().item()\n",
    "            total_prediction += prediction.shape[0]\n",
    "\n",
    "            #if i % 10 == 0:    # print every 10 mini-batches\n",
    "            #    print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 10))\n",
    "\n",
    "        # Print stats at the end of the epoch\n",
    "        num_batches = len(train_dl)\n",
    "        avg_loss = running_loss / num_batches\n",
    "        acc = correct_prediction/total_prediction\n",
    "        print(f'Epoch: {epoch}, Loss: {avg_loss:.2f}, Accuracy: {acc:.2f}')\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "4e9589b0-bb24-4b0e-b020-7882d60b1521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, epoch):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data, target in test_dataloader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "        output = output.permute(1, 0, 2)\n",
    "        pred = output.max(2)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target).cpu().sum().item()\n",
    "    print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(test_dataloader.dataset),\n",
    "        100. * correct / len(test_dataloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "1d3f7a19-46c7-44be-8d41-4008d7ab27f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 2.22, Accuracy: 0.19\n",
      "Epoch: 1, Loss: 1.97, Accuracy: 0.34\n",
      "Epoch: 2, Loss: 1.78, Accuracy: 0.40\n",
      "Epoch: 3, Loss: 1.56, Accuracy: 0.50\n",
      "Epoch: 4, Loss: 1.27, Accuracy: 0.64\n",
      "Epoch: 5, Loss: 1.07, Accuracy: 0.70\n",
      "Epoch: 6, Loss: 0.85, Accuracy: 0.77\n",
      "Epoch: 7, Loss: 0.68, Accuracy: 0.84\n",
      "Epoch: 8, Loss: 0.66, Accuracy: 0.85\n",
      "Epoch: 9, Loss: 0.48, Accuracy: 0.87\n",
      "Epoch: 10, Loss: 0.45, Accuracy: 0.90\n",
      "Epoch: 11, Loss: 0.38, Accuracy: 0.93\n",
      "Epoch: 12, Loss: 0.33, Accuracy: 0.92\n",
      "Epoch: 13, Loss: 0.32, Accuracy: 0.93\n",
      "Epoch: 14, Loss: 0.31, Accuracy: 0.94\n",
      "Epoch: 15, Loss: 0.24, Accuracy: 0.97\n",
      "Epoch: 16, Loss: 0.25, Accuracy: 0.96\n",
      "Epoch: 17, Loss: 0.27, Accuracy: 0.95\n",
      "Epoch: 18, Loss: 0.22, Accuracy: 0.97\n",
      "Epoch: 19, Loss: 0.22, Accuracy: 0.96\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20   # Just for demo, adjust this higher.\n",
    "training(model, train_dataloader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "373e0ae7-78de-435d-a078-42c0b513044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, val_dl):\n",
    "    correct_prediction = 0\n",
    "    total_prediction = 0\n",
    "\n",
    "    # Disable gradient updates\n",
    "    with torch.no_grad():\n",
    "        for data in val_dl:\n",
    "            # Get the input features and target labels, and put them on the GPU\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Normalize the inputs\n",
    "            inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "            inputs = (inputs - inputs_m) / inputs_s\n",
    "\n",
    "            # Get predictions\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Get the predicted class with the highest score\n",
    "            _, prediction = torch.max(outputs,1)\n",
    "            # Count of predictions that matched the target label\n",
    "            correct_prediction += (prediction == labels).sum().item()\n",
    "            total_prediction += prediction.shape[0]\n",
    "\n",
    "    acc = correct_prediction/total_prediction\n",
    "    print(f'Accuracy: {acc:.2f}, Total items: {total_prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a864dc-c642-4f4e-b4a6-814cf2a71528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.98, Total items: 100\n"
     ]
    }
   ],
   "source": [
    "inference(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "34f1b790-ed51-4c91-9f5f-ce8bc17d480c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding = model.lin.weight.detach().numpy()\n",
    "embedding = pd.DataFrame(embedding, index=presidents_dataset.classes)\n",
    "embedding.to_csv('dataset/audio_embedding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "0e4dd70a-03af-476f-83ef-0cc63046c241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ward_dist(cluster_a, cluster_b):\n",
    "    if len(cluster_b) != 0:\n",
    "        all_ps = np.concatenate((cluster_a, cluster_b))\n",
    "        center_all = [np.mean(all_ps[:,i]) for i in range(all_ps.shape[1])]\n",
    "        comp1 = sum([math.dist(p, center_all)**2 for p in all_ps])\n",
    "        center_a = [np.mean(cluster_a[:,i]) for i in range(cluster_a.shape[1])]\n",
    "        comp2 = sum([math.dist(p, center_a)**2 for p in cluster_a])\n",
    "        center_b = [np.mean(cluster_b[:,i]) for i in range(cluster_b.shape[1])]\n",
    "        comp3 = sum([math.dist(p, center_b)**2 for p in cluster_b])\n",
    "        return comp1 - comp2 - comp3\n",
    "    else:\n",
    "        center_a = [np.mean(cluster_a[:,i]) for i in range(cluster_a.shape[1])]\n",
    "        comp2 = sum([math.dist(p, center_a)**2 for p in cluster_a])\n",
    "        return comp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "8ed6f648-97c4-4eb9-b39b-7c649d2409ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "innov_df = pd.DataFrame(columns=['Name'] + presidents_dataset.classes)\n",
    "for president in presidents_dataset.classes:\n",
    "    dict = {}\n",
    "    my_position = embedding[(embedding.index == president)].values\n",
    "    dict['Name'] = president\n",
    "    for president2 in presidents_dataset.classes:\n",
    "        president2_position = embedding[(embedding.index == president2)].values\n",
    "        dict[president2] = 1 / (1 + ward_dist(my_position, president2_position))\n",
    "    org_sim = list(dict.values())[1:]\n",
    "    try:\n",
    "        rescaled_sim = [(i-min(org_sim)) / (max(org_sim)-min(org_sim)) for i in org_sim]\n",
    "    except:\n",
    "        rescaled_sim = [i for i in org_sim]\n",
    "    for i, president2 in enumerate(presidents_dataset.classes):\n",
    "        dict[president2] = rescaled_sim[i]\n",
    "    innov_df = innov_df.append(dict, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "0447fbf1-54e6-47ad-88b2-15a4243029c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "innov_df.to_csv('dataset/network_data/voice.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686c8979-fcf4-422b-9e82-481fd359dd12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90751f08-470b-4b94-93ab-9b20743847ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
