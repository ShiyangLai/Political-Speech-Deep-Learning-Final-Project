{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "e6d33d11-934d-48c8-bb2d-3c0f0f8ba956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchaudio librosa\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from pathlib import Path\n",
    "import torchaudio\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use(['nature', 'science', 'no-latex'])\n",
    "plt.rcParams['font.family'] = 'Times New Roman'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "13e0aebe-f781-44a9-9c6f-a4605887a5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_files(path: str, label:str, resample_rate=16000, offset=300, duration=60, slice_length=600):\n",
    "    dataset = []\n",
    "    walker = sorted(str(p) for p in Path(path).glob(f'*.mp3'))\n",
    "\n",
    "    for i, file_path in enumerate(walker):\n",
    "        path, filename = os.path.split(file_path)\n",
    "        speaker = path.split('/')[-1]\n",
    "        # Load audio as slices\n",
    "        for i, t in enumerate(range(0, slice_length, duration)):\n",
    "            waveform, _ = librosa.load(file_path, sr=resample_rate, offset=t, duration=duration, mono=True)\n",
    "            dataset.append([waveform, resample_rate, label, filename.replace('.mp3', ''), i])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "db89a3ba-9f9a-499f-b09f-38d5e16bc66a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "LyndonBJohnson = load_audio_files(f'../audio/Lyndon B. Johnson', 'Lyndon B. Johnson')\n",
    "RichardMNixon = load_audio_files(f'../audio/Richard M. Nixon', 'Richard M. Nixon')\n",
    "BillClinton = load_audio_files(f'../audio/Bill Clinton', 'Bill Clinton')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "1ab37802-0cee-468b-83d3-971769c943f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader_LyndonBJohnson = torch.utils.data.DataLoader(LyndonBJohnson, batch_size=1, shuffle=True, num_workers=2)\n",
    "trainloader_RichardMNixon = torch.utils.data.DataLoader(RichardMNixon, batch_size=1, shuffle=True, num_workers=2)\n",
    "trainloader_BillClinton = torch.utils.data.DataLoader(BillClinton, batch_size=1, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "9909f620-e95e-4842-adab-cf55d14b634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spectrogram_images(trainloader, label_dir):\n",
    "    # make directory\n",
    "    directory = f'dataset/audio_images/spectrogram/{label_dir}/'\n",
    "    if(os.path.isdir(directory)):\n",
    "        print(\"Data exists for\", label_dir)\n",
    "    else:\n",
    "        os.makedirs(directory, mode=0o777, exist_ok=True)\n",
    "        \n",
    "        for i, data in enumerate(trainloader):\n",
    "            waveform = data[0].numpy().flatten()\n",
    "            sample_rate = data[1][0]\n",
    "            label = data[2]\n",
    "\n",
    "            # create transformed waveforms\n",
    "            spectrogram = librosa.feature.mfcc(y=waveform, sr=sample_rate.numpy())\n",
    "            plt.imsave(f'dataset/audio_images/spectrogram/{label_dir}/spec_img{i}.png', spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "378a5306-3bb3-477d-852a-a6c8230e3525",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_spectrogram_images(trainloader_LyndonBJohnson, 'Lyndon B. Johnson')\n",
    "create_spectrogram_images(trainloader_RichardMNixon, 'Richard M. Nixon')\n",
    "create_spectrogram_images(trainloader_BillClinton, 'Bill Clinton')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "edab9081-bb5b-47eb-ac2f-943e0042478b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 146\n",
      "    Root location: dataset/audio_images/spectrogram/\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "# load preprocessed data\n",
    "presidents_dataset = datasets.ImageFolder(\n",
    "    root='dataset/audio_images/spectrogram/',\n",
    "    transform=transforms.Compose([transforms.ToTensor()\n",
    "                                  ])\n",
    ")\n",
    "print(presidents_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "f6d2f7b4-1f12-43ba-9c96-62b5669f2115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 116\n",
      "Testing size: 30\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.8 * len(presidents_dataset))\n",
    "test_size = len(presidents_dataset) - train_size\n",
    "presidents_train_dataset, presidents_test_dataset = torch.utils.data.random_split(presidents_dataset, [train_size, test_size])\n",
    "print(\"Training size:\", len(presidents_train_dataset))\n",
    "print(\"Testing size:\",len(presidents_test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "046c977c-eeca-4aa1-abed-9c357ca0ba12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 45, 0: 30, 2: 41})"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# labels in training set\n",
    "train_classes = [label for _, label in presidents_train_dataset]\n",
    "Counter(train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "a9034e28-8b30-48a9-9f71-00ea88cd9404",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    presidents_train_dataset,\n",
    "    batch_size=10,\n",
    "    num_workers=2,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    presidents_test_dataset,\n",
    "    batch_size=10,\n",
    "    num_workers=2,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "e8e3e50d-55d7-412d-8c3e-d9c7b1ff8e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        conv_layers = []\n",
    "        # First Convolution Block with Relu and Batch Norm. Use Kaiming Initialization\n",
    "        self.conv1 = nn.Conv2d(3, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        init.kaiming_normal_(self.conv1.weight, a=0.1)\n",
    "        self.conv1.bias.data.zero_()\n",
    "        conv_layers += [self.conv1, self.relu1, self.bn1]\n",
    "        # Second Convolution Block\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        init.kaiming_normal_(self.conv2.weight, a=0.1)\n",
    "        self.conv2.bias.data.zero_()\n",
    "        conv_layers += [self.conv2, self.relu2, self.bn2]\n",
    "        # Second Convolution Block\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        init.kaiming_normal_(self.conv3.weight, a=0.1)\n",
    "        self.conv3.bias.data.zero_()\n",
    "        conv_layers += [self.conv3, self.relu3, self.bn3]\n",
    "        # Second Convolution Block\n",
    "        self.conv4 = nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        init.kaiming_normal_(self.conv4.weight, a=0.1)\n",
    "        self.conv4.bias.data.zero_()\n",
    "        conv_layers += [self.conv4, self.relu4, self.bn4]\n",
    "        # Linear Classifier\n",
    "        self.ap = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.lin = nn.Linear(in_features=64, out_features=3)\n",
    "\n",
    "        # Wrap the Convolutional Blocks\n",
    "        self.conv = nn.Sequential(*conv_layers)\n",
    " \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Run the convolutional blocks\n",
    "        x = self.conv(x)\n",
    "        # Adaptive pool and flatten for input to linear layer\n",
    "        x = self.ap(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        # Linear layer\n",
    "        x = self.lin(x)\n",
    "        # Final output\n",
    "        return x\n",
    "model = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "422a6de7-e361-42fb-a8ed-c99a4e62b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, train_dl, num_epochs):\n",
    "    # Loss Function, Optimizer and Scheduler\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001,\n",
    "                                                steps_per_epoch=int(len(train_dl)),\n",
    "                                                epochs=num_epochs,\n",
    "                                                anneal_strategy='linear')\n",
    "\n",
    "    # Repeat for each epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_prediction = 0\n",
    "        total_prediction = 0\n",
    "\n",
    "        # Repeat for each batch in the training set\n",
    "        for i, data in enumerate(train_dl):\n",
    "            # Get the input features and target labels, and put them on the GPU\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Normalize the inputs\n",
    "            inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "            inputs = (inputs - inputs_m) / inputs_s\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Keep stats for Loss and Accuracy\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Get the predicted class with the highest score\n",
    "            _, prediction = torch.max(outputs,1)\n",
    "            # Count of predictions that matched the target label\n",
    "            correct_prediction += (prediction == labels).sum().item()\n",
    "            total_prediction += prediction.shape[0]\n",
    "\n",
    "            #if i % 10 == 0:    # print every 10 mini-batches\n",
    "            #    print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 10))\n",
    "\n",
    "        # Print stats at the end of the epoch\n",
    "        num_batches = len(train_dl)\n",
    "        avg_loss = running_loss / num_batches\n",
    "        acc = correct_prediction/total_prediction\n",
    "        print(f'Epoch: {epoch}, Loss: {avg_loss:.2f}, Accuracy: {acc:.2f}')\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "4e9589b0-bb24-4b0e-b020-7882d60b1521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, epoch):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data, target in test_dataloader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "        output = output.permute(1, 0, 2)\n",
    "        pred = output.max(2)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target).cpu().sum().item()\n",
    "    print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(test_dataloader.dataset),\n",
    "        100. * correct / len(test_dataloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "1d3f7a19-46c7-44be-8d41-4008d7ab27f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.10, Accuracy: 0.31\n",
      "Epoch: 1, Loss: 0.94, Accuracy: 0.65\n",
      "Epoch: 2, Loss: 0.77, Accuracy: 0.72\n",
      "Epoch: 3, Loss: 0.63, Accuracy: 0.78\n",
      "Epoch: 4, Loss: 0.51, Accuracy: 0.84\n",
      "Epoch: 5, Loss: 0.35, Accuracy: 0.91\n",
      "Epoch: 6, Loss: 0.22, Accuracy: 0.98\n",
      "Epoch: 7, Loss: 0.20, Accuracy: 0.97\n",
      "Epoch: 8, Loss: 0.15, Accuracy: 0.97\n",
      "Epoch: 9, Loss: 0.13, Accuracy: 0.97\n",
      "Epoch: 10, Loss: 0.13, Accuracy: 0.98\n",
      "Epoch: 11, Loss: 0.08, Accuracy: 0.99\n",
      "Epoch: 12, Loss: 0.10, Accuracy: 0.98\n",
      "Epoch: 13, Loss: 0.08, Accuracy: 1.00\n",
      "Epoch: 14, Loss: 0.04, Accuracy: 1.00\n",
      "Epoch: 15, Loss: 0.03, Accuracy: 1.00\n",
      "Epoch: 16, Loss: 0.04, Accuracy: 1.00\n",
      "Epoch: 17, Loss: 0.05, Accuracy: 1.00\n",
      "Epoch: 18, Loss: 0.05, Accuracy: 1.00\n",
      "Epoch: 19, Loss: 0.04, Accuracy: 1.00\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20   # Just for demo, adjust this higher.\n",
    "training(model, train_dataloader, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "373e0ae7-78de-435d-a078-42c0b513044c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, val_dl):\n",
    "    correct_prediction = 0\n",
    "    total_prediction = 0\n",
    "\n",
    "    # Disable gradient updates\n",
    "    with torch.no_grad():\n",
    "        for data in val_dl:\n",
    "            # Get the input features and target labels, and put them on the GPU\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Normalize the inputs\n",
    "            inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "            inputs = (inputs - inputs_m) / inputs_s\n",
    "\n",
    "            # Get predictions\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Get the predicted class with the highest score\n",
    "            _, prediction = torch.max(outputs,1)\n",
    "            # Count of predictions that matched the target label\n",
    "            correct_prediction += (prediction == labels).sum().item()\n",
    "            total_prediction += prediction.shape[0]\n",
    "\n",
    "    acc = correct_prediction/total_prediction\n",
    "    print(f'Accuracy: {acc:.2f}, Total items: {total_prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "15a864dc-c642-4f4e-b4a6-814cf2a71528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.00, Total items: 30\n"
     ]
    }
   ],
   "source": [
    "inference(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "34f1b790-ed51-4c91-9f5f-ce8bc17d480c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 64])"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lin.weight.detach().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77094e8b-06c4-4a33-ab08-e038b4fd2fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
